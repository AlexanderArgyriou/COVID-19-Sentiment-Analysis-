{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy                     # Twitter API Handling module.\n",
    "import Keys                       # Contains my personal API keys for Twitter Developer.\n",
    "from textblob import TextBlob     # AI module for sentiment measurement in a blob(text).\n",
    "# from textblob.sentiments import NaiveBayesAnalyzer, could also test sentiment like b = Blob(Text, NaiveBayesAnalyzer() ) with this analyzer.\n",
    "import preprocessor as p          # module to \"clear\" tweets.\n",
    "import pandas as pd               # pandas library for dataset representation.\n",
    "import folium                     # Module to create a map with out tweets.\n",
    "from geopy import OpenMapQuest    # identify the geographical coordinates.\n",
    "import time                       # time module for delay purposes.\n",
    "from nltk.corpus import stopwords # module to clear useless words.\n",
    "import matplotlib.pyplot as plt   # make the graph of words a bit better with a tight layout.\n",
    "from operator import itemgetter   # For sorting puposes module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTwitterAPI() :\n",
    "    \"\"\" \n",
    "     A function that connects with my\n",
    "    personal info from Keys.py to Twitter API and returns the \n",
    "    API object. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Authentication with MyTwitterDeveloper Infos.\n",
    "    Auth = tweepy.OAuthHandler( Keys.APIkey, Keys.APIkeySecret )\n",
    "    Auth.set_access_token( Keys.AccessToken, Keys.SecretAccessToken )\n",
    "\n",
    "    # API object to interact with Twitter.\n",
    "    # Second param defines a delay of 15min when we overuse the API so we can be ok with Twitter Policy.\n",
    "    # Third Argument lets us to know when we have to wait cause overuse.\n",
    "    TheAPI = tweepy.API(Auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "    \n",
    "    # return twitter's API object.\n",
    "    return TheAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGeocodes( ListOfTweets ) :\n",
    "    \"\"\" \n",
    "     A Function to customize the list of dictionaries which \n",
    "    represents tweets, and add in every dictionary the GeoLocation.latitude\n",
    "    and the GeoLocation.longitude attributes for the location of the tweet.\n",
    "    \"\"\"\n",
    "    print( \"Getting Coords...\" )\n",
    "    \n",
    "    # Connect mapquest with my personal developer API key.\n",
    "    Geo = OpenMapQuest( api_key = Keys.MapAPIKey )\n",
    "    \n",
    "    # number of tweets without locations.\n",
    "    BadLocations = 0\n",
    "    \n",
    "    # traverse the tweet list.\n",
    "    for Tweet in ListOfTweets :\n",
    "        ProcessedFlag = False\n",
    "        Delay = .1\n",
    "        GeoLocation = \"\"\n",
    "        \n",
    "        # try to see if a tweet is processed and handle a connection failure or timeout(if we trigger one).\n",
    "        while not ProcessedFlag :\n",
    "            try :\n",
    "                GeoLocation = Geo.geocode( Tweet[\"Location\"] )\n",
    "                ProcessedFlag = True\n",
    "            except :\n",
    "                print(\"Time out, trying again\")\n",
    "                time.sleep(Delay)\n",
    "                Delay += .1\n",
    "            \n",
    "            # Add {\"Latitude\" : GeoLocation.latitude} and {\"Longitude\" : GeoLocation.longitude}\n",
    "            # to our Tweet Dictionary.\n",
    "            if GeoLocation :\n",
    "                Tweet[\"Latitude\"] = GeoLocation.latitude\n",
    "                Tweet[\"Longitude\"] = GeoLocation.longitude\n",
    "            else :\n",
    "                BadLocations += 1\n",
    "    \n",
    "    print(\"GeoCoding Done\")\n",
    "    \n",
    "    # return the number of bad locations.\n",
    "    return  BadLocations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTweetContent(Tweet, Location = False) :\n",
    "    \"\"\"\n",
    "     A Function that takes a Tweet rerurned from a listener and\n",
    "    makes a dictionary for this tweet, with the usefull info we need\n",
    "    and not all tweet's info.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The dictionary which represents the tweet.\n",
    "    Fields = {}\n",
    "    \n",
    "    # { \"Screen_name\" : \"user's name who made the tweet\" }.\n",
    "    Fields[\"Screen_name\"] = Tweet.user.screen_name\n",
    "    \n",
    "    # Check if a tweet has 280 words limit and take the full text.\n",
    "    try :\n",
    "        # { \"Text\" : \"Text of the tweet\" }.\n",
    "        Fields[\"Text\"] = Tweet.extended_tweet[\"full_text\"]\n",
    "    except :\n",
    "        # { \"Text\" : \"Text of the tweet\" }.\n",
    "        Fields[\"Text\"] = Tweet.text\n",
    "    \n",
    "    # if a tweet describe the location parse it to the dictionary.\n",
    "    if Location :\n",
    "        # { \"Location\" : \"Where was the tweet from\" }.\n",
    "        Fields[\"Location\"] = Tweet.user.location\n",
    "    \n",
    "    # Return the dictionary with the tweet's info.\n",
    "    return Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawTweetsOnMap(TweetsList) :\n",
    "    \"\"\"\n",
    "     This function creates and draws the tweets on the Map.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a DataFrame from the TweetsList\n",
    "    DF = pd.DataFrame(TweetsList)\n",
    "    \n",
    "    # Drop NANs\n",
    "    DF = DF.dropna()\n",
    "    \n",
    "    # Save all the info we gained\n",
    "    DF.to_csv(\"TweetsInfo.csv\")\n",
    "    \n",
    "    # Map Creation, starts from US.\n",
    "    Map = folium.Map(location = [39.8283, -98.5795], tiles = \"Stamen Terrain\", zoom_start = 5, detect_retina = True)\n",
    "    \n",
    "    # for every Tweet in DataFrame we bring it to the map.\n",
    "    for T in DF.itertuples() :\n",
    "        Txt = \": \".join( list((T.Screen_name, T.Text)) ) \n",
    "        Popup = folium.Popup(Txt, parse_html = True)\n",
    "        \n",
    "        # Neutral emotion color\n",
    "        Marker = folium.Marker( (T.Latitude, T.Longitude), popup = Popup, icon = folium.Icon(color = \"gray\"))\n",
    "        \n",
    "        if T.Sentiment == \"-\" :\n",
    "            # Negative emotion color\n",
    "            Marker = folium.Marker( (T.Latitude, T.Longitude), popup = Popup, icon = folium.Icon(color = \"red\"))\n",
    "        elif T.Sentiment == \"+\" :\n",
    "            # Positive emotion color\n",
    "            Marker = folium.Marker( (T.Latitude, T.Longitude), popup = Popup, icon = folium.Icon(color = \"green\"))\n",
    "            \n",
    "        Marker.add_to(Map)\n",
    "\n",
    "    # Saves the Map as html\n",
    "    Map.save(\"tweet_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(tweepy.StreamListener) :\n",
    "    \"\"\"\n",
    "     This class inherits the tweepy.StreamListener interface,\n",
    "    and is responsible to \"listen and analyze tweets of a specific subject.\"\n",
    "    \"\"\"\n",
    "    def __init__(self, newAPI, newTopic, newLimit = 10) :\n",
    "        \"\"\"\n",
    "         Analyzer's Constructor which is uses the setter \n",
    "        properties of our _private objects to set them.\n",
    "        \"\"\"\n",
    "        self.CountsDict = {\"TotalTweets\" : 0, \"Locations\" : 0}           # Count the num of tweets and the Locations.\n",
    "        self.SentDict = {\"Positive\" : 0, \"Negative\" : 0, \"Neutral\" : 0}  # Ditionary to count AI predictions about the sentiment of a tweet\n",
    "        self.TweetsList = []                                             # The list of Tweets.\n",
    "        self.Topic = newTopic                                            # The topic of our listener for example tweets for football.\n",
    "        self._TWEET_LIMIT = newLimit                                     # TweetLimit CONST\n",
    "        super().__init__(newAPI)                                         # Call to tweepy.StreamListener constructor.\n",
    "        \n",
    "    @property \n",
    "    def CountsDict(self) :\n",
    "        \"\"\"Get _CountsDict.\"\"\"\n",
    "        return self._CountsDict\n",
    "    \n",
    "    @CountsDict.setter\n",
    "    def CountsDict(self, newCountsDict) :\n",
    "        \"\"\"Set _CountsDict.\"\"\"\n",
    "        self._CountsDict = newCountsDict\n",
    "    \n",
    "    @property \n",
    "    def TweetsList(self) :\n",
    "        \"\"\"Get _TweetsList.\"\"\"\n",
    "        return self._TweetsList\n",
    "    \n",
    "    @TweetsList.setter\n",
    "    def TweetsList(self, newTweetsList) :\n",
    "        \"\"\"Set _TweetsList.\"\"\"\n",
    "        self._TweetsList = newTweetsList\n",
    "    \n",
    "    @property \n",
    "    def Topic(self) :\n",
    "        \"\"\"Get _Topic.\"\"\"\n",
    "        return self._Topic\n",
    "    \n",
    "    @Topic.setter\n",
    "    def Topic(self, newTopic) :\n",
    "        \"\"\"Set _Topic.\"\"\"\n",
    "        self._Topic = newTopic\n",
    "    \n",
    "    @property \n",
    "    def SentDict(self) :\n",
    "        \"\"\"Get _SentDict.\"\"\"\n",
    "        return self._SentDict\n",
    "    \n",
    "    @Topic.setter\n",
    "    def SentDict(self, newSentDict) :\n",
    "        \"\"\"Set _SentDict.\"\"\"\n",
    "        self._SentDict = newSentDict\n",
    "        \n",
    "    def on_status(self, Status) :\n",
    "        \"\"\"\n",
    "         Override the on_status method we inherited from the base class.\n",
    "        This method handles every incoming tweet from our listener.\n",
    "        Status represent a tweet object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get a dictionary with the valuable tweet's info which we described in the definition of this function above.\n",
    "        TweetData = GetTweetContent(Status, Location = True)\n",
    "        \n",
    "        # ignore's retweets and off topic tweets.\n",
    "        if(TweetData[\"Text\"].startswith(\"RT\") or self.Topic.lower() not in TweetData[\"Text\"].lower()) :\n",
    "            return\n",
    "        \n",
    "        # +1 to overall tweets count.\n",
    "        self._CountsDict[\"TotalTweets\"] += 1\n",
    "        \n",
    "        # handles tweets without a location.\n",
    "        if not Status.user.location :\n",
    "            return\n",
    "        \n",
    "        p.set_options(p.OPT.URL, p.OPT.RESERVED)\n",
    "        TweetData[\"Text\"] = p.clean(TweetData[\"Text\"]) # Cleans the Text from urls and twitter reserved keywords.\n",
    "        # Bl = TextBlob(Text, analyzer = NaiveBayesAnalyzer()).\n",
    "        \n",
    "        # analyze through AI the sentiment of a tweet.\n",
    "        Bl = TextBlob(TweetData[\"Text\"])\n",
    "        Sentiment = \"\"\n",
    "        \n",
    "        if Bl.sentiment.polarity > 0 :\n",
    "            Sentiment = \"+\"\n",
    "            self._SentDict[\"Positive\"] += 1\n",
    "        elif Bl.sentiment.polarity < 0 :\n",
    "            Sentiment = \"-\"\n",
    "            self._SentDict[\"Negative\"] += 1\n",
    "        else :\n",
    "            Sentiment = \"\"\n",
    "            self._SentDict[\"Neutral\"] += 1\n",
    "        \n",
    "        TweetData[\"Text\"] = f\"({Sentiment}) {TweetData['Text']}\"\n",
    "        self._CountsDict[\"Locations\"] += 1 # +1 to the tweets with location\n",
    "        TweetData[\"Sentiment\"] = Sentiment # adds the Sentiment to TweetData Dictionary\n",
    "        self._TweetsList.append(TweetData) # append the dictionary to the list of dictionaries\n",
    "        #print(f\"{Status.user.screen_name} : {TweetData['Text']}\\n\") # print Name : Tweet\n",
    "        print(self._CountsDict[\"TotalTweets\"], end = \",\")\n",
    "        \n",
    "        # Return false and stop if we are above the limit of tweets.\n",
    "        return self._CountsDict[\"TotalTweets\"] <= self._TWEET_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    \"\"\"\n",
    "    Driver program.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The keyword we wanna search tweets and analyze the sentiment of them.\n",
    "    SEARCH_KEY = \"COVID-19\" \n",
    "    \n",
    "    # New API object.\n",
    "    TheAPI = CreateTwitterAPI()\n",
    "    \n",
    "    # New Analyzer object.\n",
    "    An = Analyzer(TheAPI, SEARCH_KEY, newLimit = 10_000)\n",
    "\n",
    "    # Start a sync listening.\n",
    "    TStream = tweepy.Stream(auth = TheAPI.auth, listener = An) \n",
    "    TStream.filter(track = [SEARCH_KEY], languages = [\"en\"], is_async = False)\n",
    "    \n",
    "    # Connect to OpenMapQuest API, Write the Latitude Longitude of a location from a tweet in its dictionary.\n",
    "    GetGeocodes(An.TweetsList)\n",
    "    \n",
    "    # Now we draw the the map, we pin the tweets also and savew our tweets set to a csv file.\n",
    "    DrawTweetsOnMap(An.TweetsList)\n",
    "    \n",
    "    print(\"App finished : Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some simple stats, about positive and negative tweets.\n",
    "DF_Nums = pd.read_csv(\"TweetsInfo.csv\")\n",
    "\n",
    "Total = Pos = Neg = 0\n",
    "\n",
    "for Sent in DF_Nums[\"Sentiment\"] :\n",
    "    if Sent == \"+\" :\n",
    "        Pos += 1\n",
    "    else :\n",
    "        Neg += 1\n",
    "        \n",
    "Total = Pos + Neg\n",
    "\n",
    "print(f\"Positive tweets : {Pos}\\nNegative Tweets : {Neg}\\n\\\n",
    "Total Tweets : {Total}\\nPos% : {Pos * 100 / Total:.3f}%\\nNeg% : {Neg * 100 / Total:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple stats about words on tweets.\n",
    "Txt = \"\"\n",
    "\n",
    "# Make all tweets a single text.\n",
    "for Text in DF[\"Text\"] :\n",
    "    Txt += Text\n",
    "\n",
    "# Create a TextBlob object to anylze it\n",
    "Blb = TextBlob(Txt)\n",
    "\n",
    "# Take from the Blob a Dictionary like {\"word : count\"}.\n",
    "Items = Blb.word_counts.items()\n",
    "\n",
    "# Avoid \"trash words\".\n",
    "SW = stopwords.words(\"english\")\n",
    "Items = [item for item in Items if item[0] not in SW]\n",
    "\n",
    "# Sort the words descending by number of appearances.\n",
    "Top20Words = sorted(Items, key = itemgetter(1), reverse = True)\n",
    "\n",
    "# Take top 20 of them\n",
    "Top20Words = Top20Words[1:23]\n",
    "del Top20Words[1] # trash word checked\n",
    "del Top20Words[9] # trash word checked\n",
    "# Create a DF of thos top20 words and print a graph for it.\n",
    "DF_Words = pd.DataFrame(Top20Words, columns = [\"word\", \"count\"])\n",
    "TheAxes = DF_Words.plot.bar(x = \"word\", y = \"count\", legend = False)\n",
    "plt.gcf().tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
